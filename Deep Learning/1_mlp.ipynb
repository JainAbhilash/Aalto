{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd34ea97405b3902d4925a75b46b982e",
     "grade": false,
     "grade_id": "cell-0a8316b039d048ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise 1. A multilayer perceptron network\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "The goal of this exercise is to get familiar with the basics of PyTorch and train a simple feedforward network on a real-world data set. If you are not familiar with PyTorch, there is a number of good tutorials [here](https://pytorch.org/tutorials/index.html). We recommend the following ones:\n",
    "* [What is PyTorch?](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
    "* [Autograd: Automatic Differentiation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)\n",
    "* [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n",
    "* [Neural Networks](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)\n",
    "\n",
    "This exercise consists of several tasks which require some background knowledge of basic ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "351dfcae9c688c72cab8ba805d82882c",
     "grade": false,
     "grade_id": "cell-01498dc3f73989b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# Select data directory\n",
    "import os\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    # course_data_dir = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9948c1cbf3480ee5b2a9c2a397921ec",
     "grade": false,
     "grade_id": "cell-7643a1c4336569b4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device which you are going to use for training\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc5c0195206dae40876fe429916217c4",
     "grade": false,
     "grade_id": "cell-70232a39ccf9c751",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c86a077d5d534679bd3f597ac6a6bdce",
     "grade": false,
     "grade_id": "cell-ce13efdf413792bd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "We are going to use *winequality* dataset which contains red and white vinho verde wine samples rated by experts from 0 to 10 (obtained from [here](https://archive.ics.uci.edu/ml/datasets/wine+quality)). We will transform the task into a binary classification problem and try to predict if the quality of wine is greater or lower than 7. The idea is to compare the quality of predictions obtained by a random forest classfier and a simple neural network.\n",
    "\n",
    "Let us load the data and split it into the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e33090c95b149fec5aec93c5e199a4f",
     "grade": false,
     "grade_id": "cell-bc3a08be26d3616e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from /coursedata/winequality\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(course_data_dir, 'winequality')\n",
    "print('Data loaded from %s' % data_dir)\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_csv(os.path.join(data_dir, 'winequality-red.csv'), delimiter=';'),\n",
    "    pd.read_csv(os.path.join(data_dir, 'winequality-white.csv'), delimiter=';')\n",
    "])\n",
    "\n",
    "x = df.loc[:, df.columns != 'quality'].values\n",
    "y = df['quality'].values >= 7  # Convert to a binary classification problem\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1, shuffle=True)\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "356da8829de19d89765b10c3ff4aabb3",
     "grade": false,
     "grade_id": "cell-fff001b57c687c28",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Train a Random forest classifier\n",
    "\n",
    "*In the code below, train a random forest classifier from sklearn (look at the description [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) using `x_train` and `y_train` with 100 trees. Name your classifier object `classifier`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97dc62b85ec7d20b7554e453e3e33fd5",
     "grade": false,
     "grade_id": "cell-92782487f52a6c3e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# classifier = ...\n",
    "# YOUR CODE HERE\n",
    "classifier=RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(x_train,y_train)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc8909cddf05a5f36de2499f483edede",
     "grade": true,
     "grade_id": "rf_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest: 0.89\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      1064\n",
      "           1       0.76      0.55      0.64       236\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1300\n",
      "   macro avg       0.83      0.75      0.79      1300\n",
      "weighted avg       0.88      0.89      0.88      1300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(15,0.5,'true labels')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the accuracy of the random forest classifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "pred_test = classifier.predict(x_test)  # Predict labels of test data using the trained classifier\n",
    "c_matrix = confusion_matrix(y_test, pred_test) \n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, pred_test)\n",
    "print(\"Accuracy of random forest: {:.2f}\".format(rf_accuracy))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(4, 4))\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "sns.heatmap(c_matrix, cmap='Blues', annot=True, fmt='g', cbar=False)\n",
    "ax.set_xlabel('predictions')\n",
    "ax.set_ylabel('true labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecc61bbd856ff9141c9d0de211523be2",
     "grade": false,
     "grade_id": "cell-4d94c36293bfa64e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As you can see, the random forest classifier works quite nicely in this task without much tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd8228d2186021aafe8fd809c2f229fa",
     "grade": false,
     "grade_id": "cell-76070c68689a5242",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## A multilayer perceptron (MLP) network with two hidden layers\n",
    "\n",
    "In the code below, define a neural network architecture with:\n",
    "- input dimensionality 11\n",
    "- one hidden layer with 100 units with ReLU nonlinearity\n",
    "- one hidden layer with 100 units with ReLU nonlinearity\n",
    "- linear output layer with output dimensionality 2.\n",
    "\n",
    "**Please do not use [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) in your code.**\n",
    "\n",
    "You may want to look at [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4838e01b283d2060c905d954da14d45d",
     "grade": false,
     "grade_id": "cell-c648be60aebb3433",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_inputs = 11\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.fc1=nn.Linear(n_inputs,100)\n",
    "        self.fc2=nn.Linear(100,100)\n",
    "        self.fc3=nn.Linear(100,2)\n",
    "        \n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ec8a74e5889cec8c4cbc26bf8f79a54",
     "grade": true,
     "grade_id": "mlp_architecture",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us create the network and make sure it can process a random input of the right shape\n",
    "mlp = MLP()\n",
    "y = mlp(torch.randn(10, n_inputs))\n",
    "assert y.shape == torch.Size([10, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c0975e13adc5dc011d2a5c49ce44813",
     "grade": false,
     "grade_id": "cell-4a3bd5bb745e59c6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "One can also create an instance of a simple deep network using [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential).\n",
    "\n",
    "In the cell below, please use [`torch.nn.Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n",
    "to create an MLP with the same structure as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "009519638addd8d21556ddc8039f8523",
     "grade": false,
     "grade_id": "cell-1310c88e86ee652b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# This function should return an MLP model created with torch.nn.Sequential\n",
    "# - input dimensionality 11\n",
    "# - one hidden layer with 100 units with ReLU nonlinearity\n",
    "# - one hidden layer with 100 units with ReLU nonlinearity\n",
    "# - linear output layer with output dimensionality 2.\n",
    "# mlp_seq = nn.Sequential(...\n",
    "# YOUR CODE HERE\n",
    "mlp_seq=nn.Sequential(\n",
    "        nn.Linear(n_inputs,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100,2)\n",
    "        )\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef31af1e5f75043643a15dde8696fe7",
     "grade": false,
     "grade_id": "cell-9aff5dc7e6aa2c3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the network\n",
    "print(mlp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a6a6b214f3be7581a24ed938d6a2883",
     "grade": true,
     "grade_id": "mlp_Sequential",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us feed a random input of the right shape to the network created with torch.nn.Sequential.\n",
    "y = mlp_seq(torch.randn(10, n_inputs))\n",
    "assert y.shape == torch.Size([10, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0150363a62c9680543f7697e313a5675",
     "grade": false,
     "grade_id": "cell-70cbd420870116d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Train an MLP network\n",
    "\n",
    "Next we will train the multilayer perceptron network. For better understanding of the training process you can take a look at [this part of the tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#backprop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5fa7a839ecd25901b63e914bd53ec6c",
     "grade": false,
     "grade_id": "cell-0c16db048e765d97",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Data scaling\n",
    "\n",
    "Even though deep learning is supposed to work well on raw data without much feature engineering, it is usually a good idea to pre-process data so that the inputs have zero mean and unit standard deviation. PyTorch has its own tools for preprocessing but let us use sklearn's `StandardScaler` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca402794b8fd94bda252ab568e6a620",
     "grade": false,
     "grade_id": "cell-db601500e1d7cd93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2af318ff16206e2fe8425c37fac0204c",
     "grade": false,
     "grade_id": "cell-5a5f4579c7df733f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Let us implement the training loop. We will use the Adam optimizer with learning rate 0.01 and we will process the data in the full-batch model (without splitting the data into mini-batches).\n",
    "\n",
    "*Your task is to insert the missing code. You may find it useful to look at [this tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py).*\n",
    "Your should have the following steps:\n",
    "* Transform `x_train_scaled` and `y_train` to `torch.tensor`, make sure the tensors have proper types and they go to the specified `device`.\n",
    "* Set all gradient values to zeros.\n",
    "* Calculate outputs of the MLP network (call them `outputs`).\n",
    "* Calculate cross entropy loss using [`torch.nn.functional.cross_entropy`](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.cross_entropy).\n",
    "* Backpropagate the loss: compute the gradients of the loss wrt to all the parameters of the MLP.\n",
    "* Update the parameters of the model using the `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [],
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0c2fc142dd0cdfa9399db8ec15f7f3d",
     "grade": false,
     "grade_id": "cell-692ef1b990bd1bbc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: Loss: 0.619694 Train accuracy 0.80 Test accuracy 0.82\n",
      "Train Epoch 1: Loss: 0.520542 Train accuracy 0.80 Test accuracy 0.82\n",
      "Train Epoch 2: Loss: 0.486734 Train accuracy 0.80 Test accuracy 0.82\n",
      "Train Epoch 3: Loss: 0.481585 Train accuracy 0.80 Test accuracy 0.82\n",
      "Train Epoch 4: Loss: 0.470230 Train accuracy 0.80 Test accuracy 0.82\n",
      "Train Epoch 5: Loss: 0.452169 Train accuracy 0.80 Test accuracy 0.82\n",
      "Train Epoch 6: Loss: 0.436931 Train accuracy 0.80 Test accuracy 0.83\n",
      "Train Epoch 7: Loss: 0.428293 Train accuracy 0.81 Test accuracy 0.83\n",
      "Train Epoch 8: Loss: 0.424658 Train accuracy 0.82 Test accuracy 0.83\n",
      "Train Epoch 9: Loss: 0.421962 Train accuracy 0.82 Test accuracy 0.82\n",
      "Train Epoch 10: Loss: 0.417443 Train accuracy 0.82 Test accuracy 0.82\n",
      "Train Epoch 11: Loss: 0.410922 Train accuracy 0.82 Test accuracy 0.82\n",
      "Train Epoch 12: Loss: 0.403938 Train accuracy 0.82 Test accuracy 0.83\n",
      "Train Epoch 13: Loss: 0.398165 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 14: Loss: 0.394491 Train accuracy 0.83 Test accuracy 0.84\n",
      "Train Epoch 15: Loss: 0.392618 Train accuracy 0.83 Test accuracy 0.84\n",
      "Train Epoch 16: Loss: 0.391220 Train accuracy 0.83 Test accuracy 0.84\n",
      "Train Epoch 17: Loss: 0.389141 Train accuracy 0.83 Test accuracy 0.84\n",
      "Train Epoch 18: Loss: 0.386492 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 19: Loss: 0.384046 Train accuracy 0.83 Test accuracy 0.82\n",
      "Train Epoch 20: Loss: 0.382459 Train accuracy 0.83 Test accuracy 0.82\n",
      "Train Epoch 21: Loss: 0.381530 Train accuracy 0.83 Test accuracy 0.82\n",
      "Train Epoch 22: Loss: 0.380443 Train accuracy 0.82 Test accuracy 0.82\n",
      "Train Epoch 23: Loss: 0.378720 Train accuracy 0.83 Test accuracy 0.82\n",
      "Train Epoch 24: Loss: 0.376690 Train accuracy 0.83 Test accuracy 0.82\n",
      "Train Epoch 25: Loss: 0.374889 Train accuracy 0.83 Test accuracy 0.82\n",
      "Train Epoch 26: Loss: 0.373493 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 27: Loss: 0.372225 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 28: Loss: 0.370702 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 29: Loss: 0.369017 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 30: Loss: 0.367522 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 31: Loss: 0.366356 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 32: Loss: 0.365313 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 33: Loss: 0.364087 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 34: Loss: 0.362694 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 35: Loss: 0.361383 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 36: Loss: 0.360304 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 37: Loss: 0.359298 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 38: Loss: 0.358111 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 39: Loss: 0.356742 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 40: Loss: 0.355439 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 41: Loss: 0.354327 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 42: Loss: 0.353182 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 43: Loss: 0.351866 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 44: Loss: 0.350622 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 45: Loss: 0.349595 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 46: Loss: 0.348559 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 47: Loss: 0.347358 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 48: Loss: 0.346142 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 49: Loss: 0.345017 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 50: Loss: 0.343843 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 51: Loss: 0.342624 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 52: Loss: 0.341463 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 53: Loss: 0.340290 Train accuracy 0.83 Test accuracy 0.83\n",
      "Train Epoch 54: Loss: 0.339077 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 55: Loss: 0.337958 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 56: Loss: 0.336825 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 57: Loss: 0.335625 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 58: Loss: 0.334511 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 59: Loss: 0.333347 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 60: Loss: 0.332122 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 61: Loss: 0.331026 Train accuracy 0.84 Test accuracy 0.84\n",
      "Train Epoch 62: Loss: 0.329869 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 63: Loss: 0.328752 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 64: Loss: 0.327640 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 65: Loss: 0.326528 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 66: Loss: 0.325421 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 67: Loss: 0.324260 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 68: Loss: 0.323128 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 69: Loss: 0.321997 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 70: Loss: 0.320900 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 71: Loss: 0.319773 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 72: Loss: 0.318644 Train accuracy 0.84 Test accuracy 0.83\n",
      "Train Epoch 73: Loss: 0.317536 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 74: Loss: 0.316385 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 75: Loss: 0.315261 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 76: Loss: 0.314077 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 77: Loss: 0.312865 Train accuracy 0.85 Test accuracy 0.83\n",
      "Train Epoch 78: Loss: 0.311659 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 79: Loss: 0.310429 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 80: Loss: 0.309202 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 81: Loss: 0.307958 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 82: Loss: 0.306687 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 83: Loss: 0.305402 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 84: Loss: 0.304117 Train accuracy 0.86 Test accuracy 0.84\n",
      "Train Epoch 85: Loss: 0.302804 Train accuracy 0.85 Test accuracy 0.84\n",
      "Train Epoch 86: Loss: 0.301455 Train accuracy 0.86 Test accuracy 0.84\n",
      "Train Epoch 87: Loss: 0.300101 Train accuracy 0.86 Test accuracy 0.84\n",
      "Train Epoch 88: Loss: 0.298786 Train accuracy 0.86 Test accuracy 0.84\n",
      "Train Epoch 89: Loss: 0.297498 Train accuracy 0.86 Test accuracy 0.84\n",
      "Train Epoch 90: Loss: 0.296471 Train accuracy 0.86 Test accuracy 0.85\n",
      "Train Epoch 91: Loss: 0.295696 Train accuracy 0.86 Test accuracy 0.85\n",
      "Train Epoch 92: Loss: 0.294903 Train accuracy 0.86 Test accuracy 0.85\n",
      "Train Epoch 93: Loss: 0.292327 Train accuracy 0.86 Test accuracy 0.85\n",
      "Train Epoch 94: Loss: 0.290361 Train accuracy 0.87 Test accuracy 0.85\n",
      "Train Epoch 95: Loss: 0.289851 Train accuracy 0.87 Test accuracy 0.84\n",
      "Train Epoch 96: Loss: 0.288907 Train accuracy 0.87 Test accuracy 0.85\n",
      "Train Epoch 97: Loss: 0.286844 Train accuracy 0.87 Test accuracy 0.85\n",
      "Train Epoch 98: Loss: 0.284959 Train accuracy 0.87 Test accuracy 0.85\n",
      "Train Epoch 99: Loss: 0.284298 Train accuracy 0.87 Test accuracy 0.85\n",
      "Train Epoch 100: Loss: 0.283685 Train accuracy 0.87 Test accuracy 0.84\n",
      "Train Epoch 101: Loss: 0.281629 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 102: Loss: 0.279534 Train accuracy 0.87 Test accuracy 0.85\n",
      "Train Epoch 103: Loss: 0.278583 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 104: Loss: 0.277762 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 105: Loss: 0.276562 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 106: Loss: 0.274336 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 107: Loss: 0.272758 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 108: Loss: 0.271816 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 109: Loss: 0.271153 Train accuracy 0.88 Test accuracy 0.86\n",
      "Train Epoch 110: Loss: 0.270421 Train accuracy 0.88 Test accuracy 0.84\n",
      "Train Epoch 111: Loss: 0.268473 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 112: Loss: 0.266187 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 113: Loss: 0.264484 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 114: Loss: 0.263550 Train accuracy 0.88 Test accuracy 0.85\n",
      "Train Epoch 115: Loss: 0.263316 Train accuracy 0.88 Test accuracy 0.84\n",
      "Train Epoch 116: Loss: 0.262885 Train accuracy 0.89 Test accuracy 0.86\n",
      "Train Epoch 117: Loss: 0.262007 Train accuracy 0.88 Test accuracy 0.84\n",
      "Train Epoch 118: Loss: 0.259345 Train accuracy 0.89 Test accuracy 0.85\n",
      "Train Epoch 119: Loss: 0.256941 Train accuracy 0.89 Test accuracy 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 120: Loss: 0.255694 Train accuracy 0.88 Test accuracy 0.84\n",
      "Train Epoch 121: Loss: 0.255547 Train accuracy 0.89 Test accuracy 0.85\n",
      "Train Epoch 122: Loss: 0.255266 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 123: Loss: 0.253101 Train accuracy 0.89 Test accuracy 0.85\n",
      "Train Epoch 124: Loss: 0.251003 Train accuracy 0.89 Test accuracy 0.85\n",
      "Train Epoch 125: Loss: 0.249060 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 126: Loss: 0.248272 Train accuracy 0.89 Test accuracy 0.85\n",
      "Train Epoch 127: Loss: 0.248376 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 128: Loss: 0.247807 Train accuracy 0.90 Test accuracy 0.85\n",
      "Train Epoch 129: Loss: 0.247161 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 130: Loss: 0.244878 Train accuracy 0.90 Test accuracy 0.85\n",
      "Train Epoch 131: Loss: 0.242919 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 132: Loss: 0.241498 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 133: Loss: 0.240535 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 134: Loss: 0.239497 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 135: Loss: 0.238963 Train accuracy 0.90 Test accuracy 0.85\n",
      "Train Epoch 136: Loss: 0.239293 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 137: Loss: 0.238558 Train accuracy 0.90 Test accuracy 0.85\n",
      "Train Epoch 138: Loss: 0.235817 Train accuracy 0.89 Test accuracy 0.84\n",
      "Train Epoch 139: Loss: 0.233848 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 140: Loss: 0.233094 Train accuracy 0.90 Test accuracy 0.85\n",
      "Train Epoch 141: Loss: 0.232203 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 142: Loss: 0.230396 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 143: Loss: 0.229503 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 144: Loss: 0.229716 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 145: Loss: 0.230420 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 146: Loss: 0.228462 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 147: Loss: 0.229001 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 148: Loss: 0.228152 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 149: Loss: 0.225014 Train accuracy 0.90 Test accuracy 0.85\n",
      "Train Epoch 150: Loss: 0.222597 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 151: Loss: 0.222613 Train accuracy 0.91 Test accuracy 0.85\n",
      "Train Epoch 152: Loss: 0.221546 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 153: Loss: 0.220262 Train accuracy 0.91 Test accuracy 0.85\n",
      "Train Epoch 154: Loss: 0.220583 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 155: Loss: 0.220073 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 156: Loss: 0.219138 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 157: Loss: 0.217426 Train accuracy 0.91 Test accuracy 0.85\n",
      "Train Epoch 158: Loss: 0.217581 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 159: Loss: 0.215432 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 160: Loss: 0.213024 Train accuracy 0.91 Test accuracy 0.85\n",
      "Train Epoch 161: Loss: 0.212967 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 162: Loss: 0.212410 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 163: Loss: 0.210668 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 164: Loss: 0.210100 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 165: Loss: 0.210394 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 166: Loss: 0.209979 Train accuracy 0.92 Test accuracy 0.85\n",
      "Train Epoch 167: Loss: 0.211903 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 168: Loss: 0.214453 Train accuracy 0.92 Test accuracy 0.85\n",
      "Train Epoch 169: Loss: 0.216537 Train accuracy 0.90 Test accuracy 0.84\n",
      "Train Epoch 170: Loss: 0.211248 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 171: Loss: 0.205121 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 172: Loss: 0.204417 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 173: Loss: 0.207289 Train accuracy 0.92 Test accuracy 0.85\n",
      "Train Epoch 174: Loss: 0.208805 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 175: Loss: 0.203600 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 176: Loss: 0.200325 Train accuracy 0.92 Test accuracy 0.85\n",
      "Train Epoch 177: Loss: 0.202812 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 178: Loss: 0.203189 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 179: Loss: 0.200604 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 180: Loss: 0.197519 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 181: Loss: 0.198238 Train accuracy 0.92 Test accuracy 0.85\n",
      "Train Epoch 182: Loss: 0.199639 Train accuracy 0.91 Test accuracy 0.84\n",
      "Train Epoch 183: Loss: 0.198891 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 184: Loss: 0.195644 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 185: Loss: 0.194428 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 186: Loss: 0.194728 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 187: Loss: 0.195853 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 188: Loss: 0.193526 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 189: Loss: 0.191324 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 190: Loss: 0.190471 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 191: Loss: 0.191513 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 192: Loss: 0.190324 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 193: Loss: 0.189492 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 194: Loss: 0.189132 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 195: Loss: 0.187179 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 196: Loss: 0.185986 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 197: Loss: 0.186767 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 198: Loss: 0.186252 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 199: Loss: 0.186165 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 200: Loss: 0.185129 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 201: Loss: 0.184425 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 202: Loss: 0.183215 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 203: Loss: 0.181521 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 204: Loss: 0.180289 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 205: Loss: 0.180338 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 206: Loss: 0.179567 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 207: Loss: 0.178283 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 208: Loss: 0.177950 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 209: Loss: 0.177810 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 210: Loss: 0.178678 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 211: Loss: 0.179626 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 212: Loss: 0.183973 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 213: Loss: 0.189654 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 214: Loss: 0.193165 Train accuracy 0.91 Test accuracy 0.83\n",
      "Train Epoch 215: Loss: 0.180595 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 216: Loss: 0.173121 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 217: Loss: 0.180251 Train accuracy 0.92 Test accuracy 0.83\n",
      "Train Epoch 218: Loss: 0.182205 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 219: Loss: 0.176305 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 220: Loss: 0.171696 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 221: Loss: 0.177234 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 222: Loss: 0.181558 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 223: Loss: 0.171726 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 224: Loss: 0.171508 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 225: Loss: 0.180119 Train accuracy 0.92 Test accuracy 0.84\n",
      "Train Epoch 226: Loss: 0.171648 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 227: Loss: 0.168685 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 228: Loss: 0.170662 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 229: Loss: 0.171353 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 230: Loss: 0.165508 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 231: Loss: 0.166322 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 232: Loss: 0.166668 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 233: Loss: 0.165358 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 234: Loss: 0.163437 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 235: Loss: 0.163230 Train accuracy 0.94 Test accuracy 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 236: Loss: 0.163816 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 237: Loss: 0.161961 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 238: Loss: 0.160588 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 239: Loss: 0.160837 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 240: Loss: 0.160467 Train accuracy 0.94 Test accuracy 0.86\n",
      "Train Epoch 241: Loss: 0.159658 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 242: Loss: 0.158396 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 243: Loss: 0.157922 Train accuracy 0.94 Test accuracy 0.86\n",
      "Train Epoch 244: Loss: 0.157971 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 245: Loss: 0.157197 Train accuracy 0.94 Test accuracy 0.86\n",
      "Train Epoch 246: Loss: 0.156550 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 247: Loss: 0.155679 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 248: Loss: 0.154978 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 249: Loss: 0.154688 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 250: Loss: 0.154247 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 251: Loss: 0.153874 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 252: Loss: 0.153447 Train accuracy 0.94 Test accuracy 0.86\n",
      "Train Epoch 253: Loss: 0.152735 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 254: Loss: 0.151928 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 255: Loss: 0.151408 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 256: Loss: 0.150586 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 257: Loss: 0.150037 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 258: Loss: 0.149451 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 259: Loss: 0.148893 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 260: Loss: 0.148275 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 261: Loss: 0.147986 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 262: Loss: 0.147722 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 263: Loss: 0.148080 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 264: Loss: 0.149549 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 265: Loss: 0.153144 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 266: Loss: 0.158103 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 267: Loss: 0.163934 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 268: Loss: 0.157447 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 269: Loss: 0.147335 Train accuracy 0.94 Test accuracy 0.85\n",
      "Train Epoch 270: Loss: 0.143827 Train accuracy 0.95 Test accuracy 0.84\n",
      "Train Epoch 271: Loss: 0.149377 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 272: Loss: 0.154048 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 273: Loss: 0.147656 Train accuracy 0.95 Test accuracy 0.86\n",
      "Train Epoch 274: Loss: 0.141509 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 275: Loss: 0.143107 Train accuracy 0.95 Test accuracy 0.84\n",
      "Train Epoch 276: Loss: 0.147429 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 277: Loss: 0.146751 Train accuracy 0.94 Test accuracy 0.84\n",
      "Train Epoch 278: Loss: 0.140865 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 279: Loss: 0.138825 Train accuracy 0.95 Test accuracy 0.86\n",
      "Train Epoch 280: Loss: 0.141514 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 281: Loss: 0.142777 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 282: Loss: 0.140484 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 283: Loss: 0.137040 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 284: Loss: 0.136567 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 285: Loss: 0.138335 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 286: Loss: 0.138489 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 287: Loss: 0.136998 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 288: Loss: 0.134736 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 289: Loss: 0.133826 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 290: Loss: 0.134335 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 291: Loss: 0.134875 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 292: Loss: 0.134733 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 293: Loss: 0.133237 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 294: Loss: 0.131730 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 295: Loss: 0.130896 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 296: Loss: 0.130839 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 297: Loss: 0.131156 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 298: Loss: 0.131138 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 299: Loss: 0.131001 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 300: Loss: 0.130181 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 301: Loss: 0.129301 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 302: Loss: 0.128525 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 303: Loss: 0.128020 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 304: Loss: 0.127658 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 305: Loss: 0.127193 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 306: Loss: 0.126760 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 307: Loss: 0.126026 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 308: Loss: 0.125625 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 309: Loss: 0.125670 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 310: Loss: 0.126514 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 311: Loss: 0.128210 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 312: Loss: 0.130741 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 313: Loss: 0.132525 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 314: Loss: 0.132404 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 315: Loss: 0.128533 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 316: Loss: 0.125450 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 317: Loss: 0.124125 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 318: Loss: 0.124190 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 319: Loss: 0.122380 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 320: Loss: 0.121861 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 321: Loss: 0.124347 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 322: Loss: 0.123994 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 323: Loss: 0.121921 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 324: Loss: 0.118338 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 325: Loss: 0.119505 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 326: Loss: 0.121627 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 327: Loss: 0.119120 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 328: Loss: 0.117733 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 329: Loss: 0.118871 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 330: Loss: 0.119180 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 331: Loss: 0.116303 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 332: Loss: 0.115460 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 333: Loss: 0.116392 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 334: Loss: 0.115554 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 335: Loss: 0.113431 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 336: Loss: 0.114031 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 337: Loss: 0.113987 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 338: Loss: 0.113003 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 339: Loss: 0.111705 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 340: Loss: 0.111966 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 341: Loss: 0.111831 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 342: Loss: 0.111245 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 343: Loss: 0.109965 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 344: Loss: 0.110030 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 345: Loss: 0.110324 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 346: Loss: 0.109465 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 347: Loss: 0.108813 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 348: Loss: 0.109233 Train accuracy 0.97 Test accuracy 0.85\n",
      "Train Epoch 349: Loss: 0.111118 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 350: Loss: 0.115843 Train accuracy 0.96 Test accuracy 0.83\n",
      "Train Epoch 351: Loss: 0.126525 Train accuracy 0.96 Test accuracy 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 352: Loss: 0.147621 Train accuracy 0.93 Test accuracy 0.82\n",
      "Train Epoch 353: Loss: 0.160635 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 354: Loss: 0.146386 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 355: Loss: 0.109355 Train accuracy 0.97 Test accuracy 0.83\n",
      "Train Epoch 356: Loss: 0.130122 Train accuracy 0.96 Test accuracy 0.85\n",
      "Train Epoch 357: Loss: 0.152403 Train accuracy 0.93 Test accuracy 0.84\n",
      "Train Epoch 358: Loss: 0.115263 Train accuracy 0.96 Test accuracy 0.84\n",
      "Train Epoch 359: Loss: 0.124303 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 360: Loss: 0.142984 Train accuracy 0.93 Test accuracy 0.85\n",
      "Train Epoch 361: Loss: 0.113136 Train accuracy 0.96 Test accuracy 0.83\n",
      "Train Epoch 362: Loss: 0.121381 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 363: Loss: 0.130186 Train accuracy 0.95 Test accuracy 0.85\n",
      "Train Epoch 364: Loss: 0.109064 Train accuracy 0.96 Test accuracy 0.84\n",
      "Train Epoch 365: Loss: 0.115406 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 366: Loss: 0.119234 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 367: Loss: 0.104783 Train accuracy 0.97 Test accuracy 0.84\n",
      "Train Epoch 368: Loss: 0.119354 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 369: Loss: 0.117339 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 370: Loss: 0.106382 Train accuracy 0.97 Test accuracy 0.84\n",
      "Train Epoch 371: Loss: 0.118065 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 372: Loss: 0.113945 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 373: Loss: 0.104698 Train accuracy 0.97 Test accuracy 0.84\n",
      "Train Epoch 374: Loss: 0.118415 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 375: Loss: 0.108521 Train accuracy 0.96 Test accuracy 0.86\n",
      "Train Epoch 376: Loss: 0.107620 Train accuracy 0.96 Test accuracy 0.84\n",
      "Train Epoch 377: Loss: 0.110599 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 378: Loss: 0.102920 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 379: Loss: 0.103625 Train accuracy 0.97 Test accuracy 0.85\n",
      "Train Epoch 380: Loss: 0.104260 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 381: Loss: 0.101487 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 382: Loss: 0.102331 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 383: Loss: 0.102061 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 384: Loss: 0.099884 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 385: Loss: 0.100622 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 386: Loss: 0.100154 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 387: Loss: 0.098491 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 388: Loss: 0.099082 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 389: Loss: 0.098453 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 390: Loss: 0.096511 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 391: Loss: 0.098118 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 392: Loss: 0.096003 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 393: Loss: 0.096561 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 394: Loss: 0.095655 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 395: Loss: 0.095982 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 396: Loss: 0.094553 Train accuracy 0.97 Test accuracy 0.87\n",
      "Train Epoch 397: Loss: 0.095127 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 398: Loss: 0.094347 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 399: Loss: 0.093958 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 400: Loss: 0.093595 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 401: Loss: 0.093612 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 402: Loss: 0.092772 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 403: Loss: 0.092664 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 404: Loss: 0.092452 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 405: Loss: 0.091931 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 406: Loss: 0.091753 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 407: Loss: 0.091250 Train accuracy 0.97 Test accuracy 0.86\n",
      "Train Epoch 408: Loss: 0.091273 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 409: Loss: 0.090619 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 410: Loss: 0.090461 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 411: Loss: 0.090192 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 412: Loss: 0.089899 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 413: Loss: 0.089540 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 414: Loss: 0.089212 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 415: Loss: 0.089071 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 416: Loss: 0.088674 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 417: Loss: 0.088434 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 418: Loss: 0.088049 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 419: Loss: 0.087861 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 420: Loss: 0.087601 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 421: Loss: 0.087235 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 422: Loss: 0.086999 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 423: Loss: 0.086669 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 424: Loss: 0.086430 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 425: Loss: 0.086164 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 426: Loss: 0.085874 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 427: Loss: 0.085607 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 428: Loss: 0.085300 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 429: Loss: 0.085044 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 430: Loss: 0.084784 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 431: Loss: 0.084509 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 432: Loss: 0.084270 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 433: Loss: 0.084000 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 434: Loss: 0.083719 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 435: Loss: 0.083465 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 436: Loss: 0.083194 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 437: Loss: 0.082921 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 438: Loss: 0.082656 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 439: Loss: 0.082394 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 440: Loss: 0.082133 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 441: Loss: 0.081876 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 442: Loss: 0.081628 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 443: Loss: 0.081402 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 444: Loss: 0.081211 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 445: Loss: 0.081014 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 446: Loss: 0.080818 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 447: Loss: 0.080597 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 448: Loss: 0.080358 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 449: Loss: 0.080050 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 450: Loss: 0.079731 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 451: Loss: 0.079408 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 452: Loss: 0.079110 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 453: Loss: 0.078837 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 454: Loss: 0.078570 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 455: Loss: 0.078313 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 456: Loss: 0.078063 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 457: Loss: 0.077836 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 458: Loss: 0.077614 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 459: Loss: 0.077413 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 460: Loss: 0.077268 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 461: Loss: 0.077250 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 462: Loss: 0.077306 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 463: Loss: 0.077469 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 464: Loss: 0.077426 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 465: Loss: 0.077341 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 466: Loss: 0.076795 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 467: Loss: 0.076118 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 468: Loss: 0.075421 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 469: Loss: 0.074957 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 470: Loss: 0.074724 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 471: Loss: 0.074691 Train accuracy 0.98 Test accuracy 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 472: Loss: 0.074864 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 473: Loss: 0.075199 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 474: Loss: 0.075713 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 475: Loss: 0.075928 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 476: Loss: 0.075929 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 477: Loss: 0.075261 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 478: Loss: 0.074325 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 479: Loss: 0.073232 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 480: Loss: 0.072449 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 481: Loss: 0.072135 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 482: Loss: 0.072241 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 483: Loss: 0.072693 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 484: Loss: 0.073313 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 485: Loss: 0.074200 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 486: Loss: 0.074683 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 487: Loss: 0.074951 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 488: Loss: 0.074097 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 489: Loss: 0.072834 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 490: Loss: 0.071145 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 491: Loss: 0.070006 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 492: Loss: 0.069732 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 493: Loss: 0.070212 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 494: Loss: 0.071193 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 495: Loss: 0.072103 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 496: Loss: 0.073114 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 497: Loss: 0.073199 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 498: Loss: 0.072934 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 499: Loss: 0.071331 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 500: Loss: 0.069412 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 501: Loss: 0.067895 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 502: Loss: 0.067626 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 503: Loss: 0.068374 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 504: Loss: 0.069326 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 505: Loss: 0.070216 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 506: Loss: 0.070315 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 507: Loss: 0.070059 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 508: Loss: 0.068750 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 509: Loss: 0.067227 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 510: Loss: 0.065949 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 511: Loss: 0.065601 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 512: Loss: 0.066037 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 513: Loss: 0.066742 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 514: Loss: 0.067561 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 515: Loss: 0.067943 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 516: Loss: 0.068152 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 517: Loss: 0.067524 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 518: Loss: 0.066498 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 519: Loss: 0.065011 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 520: Loss: 0.063895 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 521: Loss: 0.063465 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 522: Loss: 0.063704 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 523: Loss: 0.064408 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 524: Loss: 0.065083 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 525: Loss: 0.065789 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 526: Loss: 0.065891 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 527: Loss: 0.065784 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 528: Loss: 0.064815 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 529: Loss: 0.063659 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 530: Loss: 0.062331 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 531: Loss: 0.061470 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 532: Loss: 0.061270 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 533: Loss: 0.061588 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 534: Loss: 0.062215 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 535: Loss: 0.062789 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 536: Loss: 0.063502 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 537: Loss: 0.063670 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 538: Loss: 0.063737 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 539: Loss: 0.062863 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 540: Loss: 0.061798 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 541: Loss: 0.060414 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 542: Loss: 0.059392 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 543: Loss: 0.059025 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 544: Loss: 0.059233 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 545: Loss: 0.059725 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 546: Loss: 0.060223 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 547: Loss: 0.060832 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 548: Loss: 0.061046 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 549: Loss: 0.061278 Train accuracy 0.98 Test accuracy 0.87\n",
      "Train Epoch 550: Loss: 0.060665 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 551: Loss: 0.059824 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 552: Loss: 0.058524 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 553: Loss: 0.057423 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 554: Loss: 0.056893 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 555: Loss: 0.057022 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 556: Loss: 0.057616 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 557: Loss: 0.058349 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 558: Loss: 0.059405 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 559: Loss: 0.060039 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 560: Loss: 0.060757 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 561: Loss: 0.060221 Train accuracy 0.98 Test accuracy 0.86\n",
      "Train Epoch 562: Loss: 0.059350 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 563: Loss: 0.057457 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 564: Loss: 0.055764 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 565: Loss: 0.054902 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 566: Loss: 0.055211 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 567: Loss: 0.056249 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 568: Loss: 0.057171 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 569: Loss: 0.058064 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 570: Loss: 0.058031 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 571: Loss: 0.057655 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 572: Loss: 0.056106 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 573: Loss: 0.054465 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 574: Loss: 0.053352 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 575: Loss: 0.053308 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 576: Loss: 0.054014 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 577: Loss: 0.054771 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 578: Loss: 0.055404 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 579: Loss: 0.055334 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 580: Loss: 0.054932 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 581: Loss: 0.053795 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 582: Loss: 0.052649 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 583: Loss: 0.051775 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 584: Loss: 0.051568 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 585: Loss: 0.051882 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 586: Loss: 0.052335 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 587: Loss: 0.052765 Train accuracy 0.99 Test accuracy 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 588: Loss: 0.052810 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 589: Loss: 0.052757 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 590: Loss: 0.052210 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 591: Loss: 0.051604 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 592: Loss: 0.050793 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 593: Loss: 0.050130 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 594: Loss: 0.049754 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 595: Loss: 0.049703 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 596: Loss: 0.049864 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 597: Loss: 0.050093 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 598: Loss: 0.050389 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 599: Loss: 0.050536 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 600: Loss: 0.050814 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 601: Loss: 0.050700 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 602: Loss: 0.050647 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 603: Loss: 0.050119 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 604: Loss: 0.049582 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 605: Loss: 0.048762 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 606: Loss: 0.048082 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 607: Loss: 0.047629 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 608: Loss: 0.047482 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 609: Loss: 0.047569 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 610: Loss: 0.047800 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 611: Loss: 0.048230 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 612: Loss: 0.048746 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 613: Loss: 0.049701 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 614: Loss: 0.050314 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 615: Loss: 0.051468 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 616: Loss: 0.051847 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 617: Loss: 0.052743 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 618: Loss: 0.052641 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 619: Loss: 0.052595 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 620: Loss: 0.051610 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 621: Loss: 0.049253 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 622: Loss: 0.046488 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 623: Loss: 0.045558 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 624: Loss: 0.046286 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 625: Loss: 0.046881 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 626: Loss: 0.047489 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 627: Loss: 0.047706 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 628: Loss: 0.046893 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 629: Loss: 0.045184 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 630: Loss: 0.044534 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 631: Loss: 0.044559 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 632: Loss: 0.044629 Train accuracy 0.99 Test accuracy 0.85\n",
      "Train Epoch 633: Loss: 0.045237 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 634: Loss: 0.045537 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 635: Loss: 0.045119 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 636: Loss: 0.044252 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 637: Loss: 0.043697 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 638: Loss: 0.043152 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 639: Loss: 0.042879 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 640: Loss: 0.043175 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 641: Loss: 0.043386 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 642: Loss: 0.043380 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 643: Loss: 0.043273 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 644: Loss: 0.043033 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 645: Loss: 0.042463 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 646: Loss: 0.041976 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 647: Loss: 0.041752 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 648: Loss: 0.041590 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 649: Loss: 0.041502 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 650: Loss: 0.041590 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 651: Loss: 0.041715 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 652: Loss: 0.041700 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 653: Loss: 0.041774 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 654: Loss: 0.041709 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 655: Loss: 0.041552 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 656: Loss: 0.041153 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 657: Loss: 0.040856 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 658: Loss: 0.040493 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 659: Loss: 0.040138 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 660: Loss: 0.039870 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 661: Loss: 0.039731 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 662: Loss: 0.039648 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 663: Loss: 0.039626 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 664: Loss: 0.039720 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 665: Loss: 0.039903 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 666: Loss: 0.040193 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 667: Loss: 0.040450 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 668: Loss: 0.040955 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 669: Loss: 0.041068 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 670: Loss: 0.041283 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 671: Loss: 0.040779 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 672: Loss: 0.040195 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 673: Loss: 0.039138 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 674: Loss: 0.038300 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 675: Loss: 0.037967 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 676: Loss: 0.038147 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 677: Loss: 0.038636 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 678: Loss: 0.039150 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 679: Loss: 0.039824 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 680: Loss: 0.040041 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 681: Loss: 0.040206 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 682: Loss: 0.039573 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 683: Loss: 0.038751 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 684: Loss: 0.037554 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 685: Loss: 0.036803 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 686: Loss: 0.036774 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 687: Loss: 0.037213 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 688: Loss: 0.037769 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 689: Loss: 0.038005 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 690: Loss: 0.038138 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 691: Loss: 0.037697 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 692: Loss: 0.037100 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 693: Loss: 0.036300 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 694: Loss: 0.035737 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 695: Loss: 0.035563 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 696: Loss: 0.035713 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 697: Loss: 0.036006 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 698: Loss: 0.036220 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 699: Loss: 0.036409 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 700: Loss: 0.036252 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 701: Loss: 0.036009 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 702: Loss: 0.035459 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 703: Loss: 0.034939 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 704: Loss: 0.034541 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 705: Loss: 0.034376 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 706: Loss: 0.034407 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 707: Loss: 0.034558 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 708: Loss: 0.034813 Train accuracy 0.99 Test accuracy 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 709: Loss: 0.034981 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 710: Loss: 0.035204 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 711: Loss: 0.035163 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 712: Loss: 0.035116 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 713: Loss: 0.034695 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 714: Loss: 0.034291 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 715: Loss: 0.033715 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 716: Loss: 0.033265 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 717: Loss: 0.033041 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 718: Loss: 0.033031 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 719: Loss: 0.033174 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 720: Loss: 0.033374 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 721: Loss: 0.033643 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 722: Loss: 0.033802 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 723: Loss: 0.034041 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 724: Loss: 0.033971 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 725: Loss: 0.033942 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 726: Loss: 0.033411 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 727: Loss: 0.032801 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 728: Loss: 0.032131 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 729: Loss: 0.031785 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 730: Loss: 0.031787 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 731: Loss: 0.031984 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 732: Loss: 0.032321 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 733: Loss: 0.032563 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 734: Loss: 0.032878 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 735: Loss: 0.032840 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 736: Loss: 0.032784 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 737: Loss: 0.032270 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 738: Loss: 0.031713 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 739: Loss: 0.031058 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 740: Loss: 0.030684 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 741: Loss: 0.030635 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 742: Loss: 0.030833 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 743: Loss: 0.031130 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 744: Loss: 0.031334 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 745: Loss: 0.031552 Train accuracy 0.99 Test accuracy 0.87\n",
      "Train Epoch 746: Loss: 0.031455 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 747: Loss: 0.031264 Train accuracy 0.99 Test accuracy 0.86\n",
      "Train Epoch 748: Loss: 0.030740 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 749: Loss: 0.030231 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 750: Loss: 0.029795 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 751: Loss: 0.029597 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 752: Loss: 0.029624 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 753: Loss: 0.029768 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 754: Loss: 0.029953 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 755: Loss: 0.030039 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 756: Loss: 0.030106 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 757: Loss: 0.029920 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 758: Loss: 0.029708 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 759: Loss: 0.029315 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 760: Loss: 0.028971 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 761: Loss: 0.028701 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 762: Loss: 0.028560 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 763: Loss: 0.028524 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 764: Loss: 0.028552 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 765: Loss: 0.028635 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 766: Loss: 0.028731 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 767: Loss: 0.028893 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 768: Loss: 0.028952 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 769: Loss: 0.029073 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 770: Loss: 0.028971 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 771: Loss: 0.028878 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 772: Loss: 0.028502 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 773: Loss: 0.028102 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 774: Loss: 0.027681 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 775: Loss: 0.027423 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 776: Loss: 0.027335 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 777: Loss: 0.027390 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 778: Loss: 0.027557 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 779: Loss: 0.027730 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 780: Loss: 0.027998 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 781: Loss: 0.028104 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 782: Loss: 0.028243 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 783: Loss: 0.028014 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 784: Loss: 0.027770 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 785: Loss: 0.027218 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 786: Loss: 0.026729 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 787: Loss: 0.026407 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 788: Loss: 0.026364 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 789: Loss: 0.026535 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 790: Loss: 0.026772 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 791: Loss: 0.027135 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 792: Loss: 0.027302 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 793: Loss: 0.027444 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 794: Loss: 0.027127 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 795: Loss: 0.026774 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 796: Loss: 0.026174 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 797: Loss: 0.025718 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 798: Loss: 0.025510 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 799: Loss: 0.025571 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 800: Loss: 0.025822 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 801: Loss: 0.026074 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 802: Loss: 0.026352 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 803: Loss: 0.026328 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 804: Loss: 0.026240 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 805: Loss: 0.025814 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 806: Loss: 0.025376 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 807: Loss: 0.024948 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 808: Loss: 0.024734 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 809: Loss: 0.024723 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 810: Loss: 0.024851 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 811: Loss: 0.025069 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 812: Loss: 0.025226 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 813: Loss: 0.025428 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 814: Loss: 0.025371 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 815: Loss: 0.025231 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 816: Loss: 0.024841 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 817: Loss: 0.024475 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 818: Loss: 0.024107 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 819: Loss: 0.023920 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 820: Loss: 0.023906 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 821: Loss: 0.024002 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 822: Loss: 0.024163 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 823: Loss: 0.024290 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 824: Loss: 0.024471 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 825: Loss: 0.024401 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 826: Loss: 0.024256 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 827: Loss: 0.023906 Train accuracy 1.00 Test accuracy 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 828: Loss: 0.023594 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 829: Loss: 0.023298 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 830: Loss: 0.023132 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 831: Loss: 0.023105 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 832: Loss: 0.023172 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 833: Loss: 0.023328 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 834: Loss: 0.023458 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 835: Loss: 0.023667 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 836: Loss: 0.023692 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 837: Loss: 0.023772 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 838: Loss: 0.023519 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 839: Loss: 0.023226 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 840: Loss: 0.022774 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 841: Loss: 0.022450 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 842: Loss: 0.022320 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 843: Loss: 0.022370 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 844: Loss: 0.022565 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 845: Loss: 0.022791 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 846: Loss: 0.023102 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 847: Loss: 0.023163 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 848: Loss: 0.023188 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 849: Loss: 0.022832 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 850: Loss: 0.022413 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 851: Loss: 0.021927 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 852: Loss: 0.021670 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 853: Loss: 0.021657 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 854: Loss: 0.021809 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 855: Loss: 0.022059 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 856: Loss: 0.022228 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 857: Loss: 0.022467 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 858: Loss: 0.022370 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 859: Loss: 0.022127 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 860: Loss: 0.021638 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 861: Loss: 0.021244 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 862: Loss: 0.021038 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 863: Loss: 0.021059 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 864: Loss: 0.021237 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 865: Loss: 0.021416 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 866: Loss: 0.021603 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 867: Loss: 0.021528 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 868: Loss: 0.021363 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 869: Loss: 0.021010 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 870: Loss: 0.020692 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 871: Loss: 0.020491 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 872: Loss: 0.020464 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 873: Loss: 0.020582 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 874: Loss: 0.020736 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 875: Loss: 0.020899 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 876: Loss: 0.020894 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 877: Loss: 0.020889 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 878: Loss: 0.020636 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 879: Loss: 0.020369 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 880: Loss: 0.020064 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 881: Loss: 0.019892 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 882: Loss: 0.019879 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 883: Loss: 0.019980 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 884: Loss: 0.020137 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 885: Loss: 0.020230 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 886: Loss: 0.020310 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 887: Loss: 0.020167 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 888: Loss: 0.019948 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 889: Loss: 0.019646 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 890: Loss: 0.019421 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 891: Loss: 0.019315 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 892: Loss: 0.019318 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 893: Loss: 0.019410 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 894: Loss: 0.019492 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 895: Loss: 0.019585 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 896: Loss: 0.019544 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 897: Loss: 0.019493 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 898: Loss: 0.019292 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 899: Loss: 0.019081 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 900: Loss: 0.018878 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 901: Loss: 0.018761 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 902: Loss: 0.018734 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 903: Loss: 0.018777 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 904: Loss: 0.018883 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 905: Loss: 0.018975 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 906: Loss: 0.019097 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 907: Loss: 0.019066 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 908: Loss: 0.018992 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 909: Loss: 0.018728 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 910: Loss: 0.018455 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 911: Loss: 0.018251 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 912: Loss: 0.018185 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 913: Loss: 0.018233 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 914: Loss: 0.018347 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 915: Loss: 0.018520 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 916: Loss: 0.018585 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 917: Loss: 0.018665 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 918: Loss: 0.018504 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 919: Loss: 0.018289 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 920: Loss: 0.017951 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 921: Loss: 0.017731 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 922: Loss: 0.017675 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 923: Loss: 0.017749 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 924: Loss: 0.017917 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 925: Loss: 0.018047 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 926: Loss: 0.018164 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 927: Loss: 0.018046 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 928: Loss: 0.017864 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 929: Loss: 0.017535 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 930: Loss: 0.017291 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 931: Loss: 0.017206 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 932: Loss: 0.017265 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 933: Loss: 0.017410 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 934: Loss: 0.017519 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 935: Loss: 0.017607 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 936: Loss: 0.017513 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 937: Loss: 0.017362 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 938: Loss: 0.017078 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 939: Loss: 0.016862 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 940: Loss: 0.016752 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 941: Loss: 0.016769 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 942: Loss: 0.016866 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 943: Loss: 0.016958 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 944: Loss: 0.017033 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 945: Loss: 0.016961 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 946: Loss: 0.016849 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 947: Loss: 0.016629 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 948: Loss: 0.016448 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 949: Loss: 0.016322 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 950: Loss: 0.016284 Train accuracy 1.00 Test accuracy 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 951: Loss: 0.016308 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 952: Loss: 0.016353 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 953: Loss: 0.016429 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 954: Loss: 0.016433 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 955: Loss: 0.016395 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 956: Loss: 0.016264 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 957: Loss: 0.016176 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 958: Loss: 0.016030 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 959: Loss: 0.015895 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 960: Loss: 0.015803 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 961: Loss: 0.015766 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 962: Loss: 0.015777 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 963: Loss: 0.015820 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 964: Loss: 0.015884 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 965: Loss: 0.015918 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 966: Loss: 0.015951 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 967: Loss: 0.015864 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 968: Loss: 0.015770 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 969: Loss: 0.015589 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 970: Loss: 0.015438 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 971: Loss: 0.015318 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 972: Loss: 0.015269 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 973: Loss: 0.015287 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 974: Loss: 0.015339 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 975: Loss: 0.015428 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 976: Loss: 0.015453 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 977: Loss: 0.015454 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 978: Loss: 0.015324 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 979: Loss: 0.015171 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 980: Loss: 0.014991 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 981: Loss: 0.014880 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 982: Loss: 0.014851 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 983: Loss: 0.014888 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 984: Loss: 0.014985 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 985: Loss: 0.015053 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 986: Loss: 0.015141 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 987: Loss: 0.015060 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 988: Loss: 0.014898 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 989: Loss: 0.014667 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 990: Loss: 0.014513 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 991: Loss: 0.014450 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 992: Loss: 0.014462 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 993: Loss: 0.014522 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 994: Loss: 0.014584 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 995: Loss: 0.014636 Train accuracy 1.00 Test accuracy 0.87\n",
      "Train Epoch 996: Loss: 0.014560 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 997: Loss: 0.014475 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 998: Loss: 0.014307 Train accuracy 1.00 Test accuracy 0.86\n",
      "Train Epoch 999: Loss: 0.014168 Train accuracy 1.00 Test accuracy 0.86\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "mlp.to(device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.005)\n",
    "n_epochs = 1000\n",
    "\n",
    "train_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "x_train_scaled=torch.tensor(x_train_scaled,device=device, dtype=torch.float)\n",
    "y_train=torch.tensor(y_train,device=device, dtype=torch.long)\n",
    "for epoch in range(n_epochs):\n",
    "    # - You need to specify dtype when converting data to torch.tensor\n",
    "    # - Call the outputs of the model \"outputs\" like in the line below\n",
    "    # outputs =  mlp.forward(...)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    outputs = mlp.forward(x_train_scaled)\n",
    "    loss = F.cross_entropy(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    if skip_training:\n",
    "        break\n",
    "\n",
    "    if (epoch % 1) == 0:\n",
    "        # Store the progress of training\n",
    "        with torch.no_grad():\n",
    "            # outputs is the output of the model produced with forward function\n",
    "            logits = outputs.cpu().data.numpy()\n",
    "            pred_train = logits.argmax(axis=1)\n",
    "            train_accuracy = accuracy_score(pred_train, y_train)\n",
    "\n",
    "            # Compute test error\n",
    "            x = torch.tensor(x_test_scaled, device=device, dtype=torch.float)\n",
    "            outputs = mlp.forward(x)\n",
    "            logits = outputs.cpu().data.numpy()\n",
    "            pred_test = logits.argmax(axis=1)\n",
    "            test_accuracy = accuracy_score(pred_test, y_test)\n",
    "            train_accuracy_history.append(train_accuracy)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            print('Train Epoch {}: Loss: {:.6f} Train accuracy {:.2f} Test accuracy {:.2f}'.format(\n",
    "                epoch, loss.item(), train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy should be comparable to the accuracy of the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43a179bfe2aaecbafa492f455d9e4694",
     "grade": true,
     "grade_id": "mlp_accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 1_mlp.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the network to a file, submit this file together with your notebook\n",
    "filename = '1_mlp.pth'\n",
    "if not skip_training:\n",
    "    try:\n",
    "        do_save = input('Do you want to save the model (type yes to confirm)? ').lower()\n",
    "        if do_save == 'yes':\n",
    "            torch.save(mlp.state_dict(), filename)\n",
    "            print('Model saved to %s' % filename)\n",
    "        else:\n",
    "            print('Model not saved')\n",
    "    except:\n",
    "        raise Exception('The notebook should be run or validated with skip_training=False.')\n",
    "else:\n",
    "    mlp = MLP()\n",
    "    mlp.load_state_dict(torch.load(filename, map_location=lambda storage, loc: storage))\n",
    "    print('Model loaded from %s' % filename)\n",
    "    mlp = mlp.to(device)\n",
    "    mlp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1408a9336753e05a66921a09ada8acca",
     "grade": false,
     "grade_id": "cell-ffa1381201dcd251",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1fba475128>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us plot the accuracies during training\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.plot(train_accuracy_history, label='train')\n",
    "ax.plot(test_accuracy_history, label='test')\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6863798cde48e5895341793793d12196",
     "grade": false,
     "grade_id": "cell-339dff5131009354",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      1064\n",
      "           1       0.63      0.62      0.62       236\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1300\n",
      "   macro avg       0.77      0.77      0.77      1300\n",
      "weighted avg       0.86      0.86      0.86      1300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(15,0.5,'true labels')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAAEWCAYAAACuU8gIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFUJJREFUeJzt3XmYFNW5x/HvC2NkEEQHhgHcUBaJEFEkGhEVEXcERHFDr7KIGjHykLjE63W9SfDGEI0aI7ivRIhRgqC4K24sLiAuqBEXNhEYGHBAZnzvH11DWpilOVBT3czv8zz9TFWdU6feYWZ+nKqu7jZ3R0QkRL2kCxCR3KUAEZFgChARCaYAEZFgChARCaYAEZFgCpA6wszyzexfZrbSzMZvwTgDzWzq1qwtKWZ2qJl9nHQducx0H0h2MbMzgZFAB6AEeBf4nbtP28JxzwYuBrq5e9kWF5rlzMyBdu7+adK1bMs0A8kiZjYSuBn4PVAE7A78Fei7FYbfA5hXF8IjE2aWl3QN2wR31yMLHkATYDUwoJo+25MKmIXR42Zg+6itB/A18GvgG2ARMChquw74HlgfHWMIcC3wUNrYrQEH8qL1c4F/k5oFfQ4MTNs+LW2/bsAMYGX0tVta20vADcBr0ThTgWZVfG8V9V+WVn8/4HhgHrAcuDKt/4HAG0Bx1Pc24CdR2yvR97Im+n5PSxv/cmAx8GDFtmifNtExukTrrYBvgR5J/25k8yPxAvSIfhBwLFBW8QdcRZ/rgTeB5kAh8DpwQ9TWI9r/emC76A/vO2DnqH3jwKgyQIAdgFXA3lFbS6BjtLwhQIACYAVwdrTfGdF606j9JeAzoD2QH62PquJ7q6j/6qj+84ClwCNAY6AjsBbYK+p/APCL6LitgQ+BEWnjOdC2kvFvJBXE+ekBEvU5LxqnIfAMcFPSvxfZ/tApTPZoCnzr1Z9iDASud/dv3H0pqZnF2Wnt66P29e4+mdT/vnsH1vMD0MnM8t19kbvPraTPCcAn7v6gu5e5+6PAR8CJaX3udfd57l4KPAbsV80x15O63rMeGAc0A25x95Lo+HOBfQHcfZa7vxkddz5wJ3B4Bt/TNe6+LqrnR9x9LPAJ8Bap0PzvGsar8xQg2WMZ0KyGc/NWwBdp619E2zaMsVEAfQc02txC3H0NqWn/BcAiM3vKzDpkUE9FTbukrS/ejHqWuXt5tFzxB74krb20Yn8za29mk8xssZmtInXdqFk1YwMsdfe1NfQZC3QCbnX3dTX0rfMUINnjDVJT9H7V9FlI6mJohd2jbSHWkJqqV2iR3ujuz7j7UaT+J/6I1B9WTfVU1LQgsKbNcQeputq5+47AlYDVsE+1TzmaWSNS15XuBq41s4KtUei2TAGSJdx9Janz/9vNrJ+ZNTSz7czsODP7v6jbo8BVZlZoZs2i/g8FHvJd4DAz293MmgC/rWgwsyIz62NmOwDrSJ0KlVcyxmSgvZmdaWZ5ZnYasA8wKbCmzdGY1HWa1dHs6MKN2pcAe23mmLcAs9x9KPAU8LctrnIbpwDJIu4+mtQ9IFeRuoD4FTAceCLq8r/ATGA2MAd4O9oWcqxngb9HY83ix3/09Ug9m7OQ1DMThwO/rGSMZUDvqO8yUs+g9Hb3b0Nq2ky/Ac4k9ezOWFLfS7prgfvNrNjMTq1pMDPrS+pC9gXRppFAFzMbuNUq3gbpRjIRCaYZiIgEU4CISDAFiIgEU4CISLCsfUFR/v7DdXU3R62YcVvSJcgWaJBX4/00G2gGIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEkwBIiLBFCAiEiwv6QK2VRed0YNB/bthZtz7+Gvc9shLPDhqEO1aFwGwU+N8iktK+cXpozj9uK6MOKfXhn1/1q4VB59xI7PnLUioekn34P338fg/xmNmtGvXnut/9wfOHzqI79asAWD58mV0+tm+3HzrXxOutPYpQGKwT5uWDOrfjUPP/iPfry9n4u2/ZMq0uZx9xb0b+owaeRIrV5cCMG7KTMZNmQlAx7atGP/nYQqPLLFkyRIeefgB/jlxMg0aNODSkZfw9OSnuO/BRzb0GXnJxRzR88gEq0xObKcwZtbBzC43s7+Y2S3R8k/jOl426bBnC6bPmU/p2vWUl//Aq7M+pe8RnX/U5+SjuvDY07M22ffUYw+odLskp7y8nHVr11JWVkbp2rUUNm++oW3NmtVMn/4mRxzZq5oRtl2xBIiZXQ6MAwyYDsyIlh81syviOGY2mfvZQrp3aUtBkx3Ib7Adx3bvyK4tdt7QfkiXNixZXsJnXy7dZN9Tju7CY0/PrM1ypRpFRUWcc+5gjul1BL16dKdxo0Z0O6T7hvYXnnuOgw46mEaNGiVYZXLiOoUZAnR09/XpG81sNDAXGFXZTmY2DBgGkLdrD/KadYypvHh9/PkS/nTfs0y6YzhrStcxe94CysrKN7SfemxXxlcSEj/vtAffrV3PB58tqs1ypRqrVq7kxReeZ/LU52ncuDGXjryESf96kt4n9gVgyuRJ9D95QMJVJieuU5gfgFaVbG8ZtVXK3ce4e1d375qr4VHh/ifeoNuZN3LUkJtZsXINn0azjfr169G3Z2cmPPP2JvsMOOYAzT6yzJtvvs4uu+5KQUEB2223HUf2Opr33nkHgOLiFbw/Zw6HHt4j2SITFNcMZATwvJl9AnwVbdsdaAsMj+mYWaVw50YsXbGa3VrsTN+enelxzp8A6HnQ3sybv4QF3xT/qL+Z0f+o/ek15OYkypUqtGjZitnvvUdpaSkNGjTgrTffYJ9OnQCY+szTHHZ4D7bffvuEq0xOLAHi7k+bWXvgQGAXUtc/vgZmuHt5tTtvIx69aSgFO+3A+rJyRox6jOKS1DMuqVnGphdJu3dpy4IlxcxfsKy2S5Vq7LtvZ446+hhOH3AS9evn0eGnP+WUAacB8MyUyQwecl7CFSbL3D3pGiqVv//w7CxMarRixm1JlyBboEEelmlf3YkqIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISrMYAMbNDzGyHaPksMxttZnvEX5qIZLtMZiB3AN+ZWWfgMuAL4IFYqxKRnJBJgJR56vMv+wK3uPstQON4yxKRXJDJh2uXmNlvgbOAw8ysPrBdvGWJSC7IZAZyGrAOGOLui4FdgD/GWpWI5IQaZyBRaIxOW/8SXQMREaoJEDMrAbyyJsDdfcfYqhKRnFBlgLi7LpSKSLUyupHMzLqb2aBouZmZ7RlvWSKSCzK5kewa4HLgt9GmnwAPxVmUiOSGTGYgJwF9gDUA7r4Q3QciImQWIN9HN5I5QMVt7SIimQTIY2Z2J7CTmZ0HPAeMjbcsEckFmdwHcpOZHQWsAtoDV7v7s7FXJiJZL5Nb2QHmAPmkTmPmxFeOiOSSTJ6FGQpMB/oDpwBvmtnguAsTkeyXyQzkUmB/d18GYGZNgdeBe+IsTESyXyYXUb8GStLWS4Cv4ilHRHJJda+FGRktLgDeMrMnSV0D6UvqlEZE6rjqTmEqbhb7LHpUeDK+ckQkl1T3YrrrarMQEck9NV5ENbNCUu+F2hFoULHd3XvGWJeI5IBMLqI+DHwE7AlcB8wHZsRYk4jkiEwCpKm73w2sd/eX3X0w8IuY6xKRHJDJfSDro6+LzOwEYCGwa3wliUiusNQLbavpYNYbeBXYDbgV2BG4zt0nxlnY2rJK305RckDJ2rKkS5AtUNgozzLtW2OAJEUBkrsUILltcwKkuhvJbqXyN1UGwN1/tZl1icg2prprIDNrrQoRyUk6hZGtTqcwuW1zTmEyeld2EZHKKEBEJJgCRESCZfKOZO3N7Hkzez9a39fMroq/NBHJdpnMQMaS+lCp9QDuPhs4Pc6iRCQ3ZBIgDd194zcQ0mV2EckoQL41szb854OlTgEWxVqViOSETF5MdxEwBuhgZguAz4GzYq1KRHJCxjeSRR9pWc/dS2rsvBXoRrLcpRvJcttWeS1MBTO7eqN1ANz9+s2uTES2KZmcwqxJW24A9AY+jKccEcklm/1aGDPbHpjo7sfEU1KKTmFyl05hclvcr4VpCOwVsJ+IbGMyuQYyh/+8L0h9oBDQ9Q8RyegaSO+05TJgibtrjioi1QeImdUDnnL3TrVUj4jkkGqvgbj7D8B7ZrZ7LdUjIjkkk1OYlsBcM5tO2lO67t4ntqpEJCdkEiD6jFwRqVQmAXK8u1+evsHMbgRejqckEckVmdwHclQl247b2oWISO6p7nNhLgR+CexlZrPTmhoDr8VdmIhkvypvZTezJsDOwB+AK9KaStx9edyF6Vb23KVb2XObPtpSEqUAyW36XBgRqRUKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKEBEJpgARkWAKkFrw8IP3079vb07qcwIPPXAfACuLizl/6CBOPO5ozh86iFUrVyZbpGzw++uuonevQzn71L6btD3ywL10P6AjxStWbNj29szpnHtGf84a0Ifh551Tm6UmTgESs08+mcc/Jozn4XHjGf/4k7zy8kt88cV87rlrDAcedDD/mjKVAw86mLvvGpN0qRI5/sR+/OnWOzfZvmTxIma+9TpFLVpu2FZSsorRo25g1OjbeGj8RG64cXRtlpo4BUjMPv/3Z+zbuTP5+fnk5eVxQNef88Jzz/Lii8/Tp18/APr068eLLzyXcKVSYb8uXdmxSZNNtt86+kYuvOTXmP3nY1OenfIUh/XsRYuWrQDYuaBprdWZDRQgMWvbtj2zZs6kuHgFpaWlTHv1FRYvXszyZcsoLGwOQGFhc5Yvj/3D/mQLTHv5BZoVFtGufYcfbf/qy/mUrFrF8GHnMnjgAKZMejKhCpNR5WfjxsXMBrn7vVW0DQOGAdz21zsZct6wWq0tDnu1acOgIUM5f+hgGjZsSPu99yavfv2ky5LNsLa0lPvvHsOfbx+7SVt5eTkff/gBt/ztbtatXccFg86k4886s/serWu/0ATUeoAA1wGVBoi7jwHGwLb10Zb9Tx5A/5MHAPCXm0dTVFREQdOmLF36DYWFzVm69BsKCgoSrlKqsuDrr1i0cAHnntEfgKXfLGHwwFMY+8A4CpsX0WSnncnPb0h+fkM6d+nKp/M+rjMBEsspjJnNruIxByiK45jZbNmyZQAsWriQ55+bynHH96bHET2Z+MQTAEx84gmOOOLIJEuUarRp155Jz73KhEnPMmHSsxQ2L+KehyfQtFkhh/boyex3ZlFWVsba0lI+eH82rffcK+mSa01cM5Ai4BhgxUbbDXg9pmNmrV+PuJiVxcXk5eVx5VXXsGOTJgweOoxLR47giccn0KJlS24afUvSZUrkmit/w7szZ1BcXMxJx/VkyPkX0bvfyZX2bb1nGw7q1p1zTz8Jq1ePE/udzF5t29Vyxckx961/pmBmdwP3uvu0StoecfczaxpjWzqFqWtK1pYlXYJsgcJGeVZzr5RYAmRrUIDkLgVIbtucANHTuCISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISTAEiIsEUICISzNw96RrqJDMb5u5jkq5Dwujnl6IZSHKGJV2AbBH9/FCAiMgWUICISDAFSHLq/PlzjtPPD11EFZEtoBmIiARTgIhIMAVIAszsWDP72Mw+NbMrkq5HMmdm95jZN2b2ftK1ZAMFSC0zs/rA7cBxwD7AGWa2T7JVyWa4Dzg26SKyhQKk9h0IfOru/3b374FxQN+Ea5IMufsrwPKk68gWCpDatwvwVdr619E2kZyjAKl9Vsk2PZcuOUkBUvu+BnZLW98VWJhQLSJbRAFS+2YA7cxsTzP7CXA6MDHhmkSCKEBqmbuXAcOBZ4APgcfcfW6yVUmmzOxR4A1gbzP72syGJF1TknQru4gE0wxERIIpQEQkmAJERIIpQEQkmAJERIIpQCSYma2OvrYyswk19B1hZg3T1ieb2U5x1yjx0tO48iNmVt/dyzPsu9rdG2XYdz7Q1d2/3ZL6JLtoBlKHmFlrM/vIzO43s9lmNsHMGprZfDO72symAQPMrI2ZPW1ms8zsVTPrEO2/p5m9YWYzzOyGjcZ9P1qub2Y3mdmc6BgXm9mvgFbAi2b2YtRvvpk1i5ZHmtn70WNE2pgfmtlYM5trZlPNLD9q+5WZfRCNP65W/xHlx9xdjzryAFqTeuHeIdH6PcBvgPnAZWn9ngfaRcsHAS9EyxOB/4qWLwJWp437frR8IfAPIC9aL4i+zgeapR1jPtAMOACYA+wANALmAvtHY5YB+0X9HwPOipYXAttHyzsl/e9alx+agdQ9X7n7a9HyQ0D3aPnvAGbWCOgGjDezd4E7gZZRn0OAR6PlB6sYvxfwN0/dso+71/TeGd2Bf7r7GndfDTwOHBq1fe7u70bLs0iFCsBs4GEzO4tUyEhC8pIuQGrdxhe9KtbXRF/rAcXuvl+G+2/MMuizcf+qrEtbLgfyo+UTgMOAPsD/mFnHisCS2qUZSN2zu5kdHC2fAUxLb3T3VcDnZjYAwFI6R82vkXr1MMDAKsafClxgZnnR/gXR9hKgcSX9XwH6RddidgBOAl6tqngzqwfs5u4vApcBO5E69ZEEKEDqng+Bc8xsNlAA3FFJn4HAEDN7j9Q1iYq3XLwEuMjMZgBNqhj/LuBLYHa0/5nR9jHAlIqLqBXc/W1S7zM6HXgLuMvd36mm/vrAQ2Y2B3gH+LO7F1fTX2Kkp3HrEDNrDUxy904JlyLbCM1ARCSYZiAiEkwzEBEJpgARkWAKEBEJpgARkWAKEBEJ9v9UwN/bajysvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's print the classification report and plot the confusion matrix similarly to the random forest classifier.\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, pred_test))\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, pred_test)\n",
    "fig, ax = plt.subplots(1, figsize=(4, 4))\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "sns.heatmap(c_matrix, cmap='Blues', annot=True, fmt='g', cbar=False)\n",
    "ax.set_xlabel('predictions')\n",
    "ax.set_ylabel('true labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "750c239eaa2372aeea5e6154ee2b6f4b",
     "grade": false,
     "grade_id": "cell-ebc09a57c4ef9976",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that even though the random forest classifier may have better performance, the performance of the MLP network may be improved by tuning the hyperparameters, such as:\n",
    "* number of hidden units\n",
    "* number of layers\n",
    "* learning rate schedule\n",
    "* regularization methods.\n",
    "\n",
    "The message from this exercise is that in simple problems that do not have spatial (like in images) or temporal (like in time series) structure, alternative classifiers (like random forests) may do very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5478f97bfe97677a086b82e96d9ede7d",
     "grade": false,
     "grade_id": "cell-94367a22998608a6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Define an MLP with an arbitrary number of layers\n",
    "\n",
    "Let us now define a multilayer perceptron with an arbitrary number of layers and arbitrary number of neurons in each layer, so that an MLP can be created as follows:\n",
    "```python\n",
    "> mlp = FancyMLP([11, 150, 100, 50, 2], activation_fn=F.tanh)\n",
    "```\n",
    "In the example above, we created a network with three hidden layers: 150 units in the first hidden layer, 100 units in the second one and 50 units in the third one.\n",
    "\n",
    "Note: The same activation function should be applied to all the layers except for the last one. This way the MLP can be used either for regression or classification.\n",
    "\n",
    "Hints:\n",
    "* You may find it useful to use function [`torch.nn.Module.add_module`](https://pytorch.org/docs/master/nn.html#torch.nn.Module.add_module) or class [`torch.nn.ModuleList`](https://pytorch.org/docs/stable/nn.html#torch.nn.ModuleList).\n",
    "* Check how many trainable parameters a created MLP has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e68c9905776a8285d6d7a49edf390de",
     "grade": false,
     "grade_id": "cell-02639f9ae9ca2c7c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Module):\n",
    "    def __init__(self, sizes, activation_fn=torch.tanh):\n",
    "        \"\"\"Multilayer perceptron with an arbitrary number of layers.\n",
    "        \n",
    "        Args:\n",
    "          sizes (list):             Number of units in each layer including the input and the output layer:\n",
    "                                    [n_inputs, n_units_in_hidden_layer1, ..., n_units_in_hidden_layerN, n_outputs]\n",
    "          activation_fn (callable): An element-wise function used in every layer except in the last one.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(FancyMLP, self).__init__()\n",
    "        self.sizes=sizes\n",
    "        #print(len(self.sizes))\n",
    "        self.activation_fn=activation_fn\n",
    "        #self.layers={}\n",
    "        #for i in range(0,len(sizes)-1):\n",
    "            #self.layers[i]=nn.Linear(sizes[i],sizes[i+1])\n",
    "        #raise NotImplementedError()\n",
    "        self.linears=nn.ModuleList([nn.Linear(sizes[i],sizes[i+1]) for i in range(0,len(sizes)-1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        for i in range(0,len(self.linears)):\n",
    "            if i!= len(self.linears)-1:\n",
    "                x=self.activation_fn(self.linears[i](x))\n",
    "            else:\n",
    "                x=self.linears[i](x)\n",
    "        return x\n",
    "        #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36bcec862f655931e3615b08ba016771",
     "grade": true,
     "grade_id": "fancy_mlp",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Let us now test your class\n",
    "mlp = FancyMLP([n_inputs, 100, 50, 2])\n",
    "y = mlp(torch.randn(10, n_inputs))\n",
    "assert y.shape == torch.Size([10, 2]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "mlp = FancyMLP([3, 10, 30, 40, 50, 5])\n",
    "y = mlp(torch.randn(10, 3))\n",
    "assert y.shape == torch.Size([10, 5]), \"Bad shape of y: y.shape={}\".format(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2fdc53bcc62d2b9103d8a83d599664d",
     "grade": true,
     "grade_id": "fancy_mlp_nparams",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FancyMLP(\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=30, bias=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): Linear(in_features=40, out_features=50, bias=True)\n",
       "    (4): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the MLP\n",
    "mlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
